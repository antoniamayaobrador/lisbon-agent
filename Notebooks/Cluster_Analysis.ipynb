{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# LISBON GEOSPATIAL ANALYSIS\n",
    "import geopandas as gpd\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import plotly.express as px\n",
    "import plotly.graph_objects as go\n",
    "import os\n",
    "import numpy as np\n",
    "import json\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "# Set Plotly default theme\n",
    "import plotly.io as pio\n",
    "pio.templates.default = \"plotly_white\"\n",
    "\n",
    "def normalize_freguesia(df, col_name):\n",
    "    if col_name in df.columns:\n",
    "        df['Freguesia_Norm'] = df[col_name].str.strip().str.upper()\n",
    "    return df\n",
    "\n",
    "def plot_choropleth(gdf, column, title, cmap='viridis', vmin=None, vmax=None, categorical=False):\n",
    "    \"\"\"\n",
    "    Consistent plotting function using Plotly for interactivity.\n",
    "    \"\"\"\n",
    "    # Check if column exists\n",
    "    if column not in gdf.columns:\n",
    "        print(f\"Column {column} not found. Skipping.\")\n",
    "        return\n",
    "\n",
    "    # Reproject to WGS84 for Mapbox\n",
    "    gdf_4326 = gdf.to_crs(\"EPSG:4326\")\n",
    "    \n",
    "    # Create Hover Data\n",
    "    hover_data = {'Freguesia_Norm': True, column: True}\n",
    "    \n",
    "    # Handle Colormap mapping (Matplotlib names to Plotly names/lists)\n",
    "    color_scale = cmap\n",
    "    if cmap == 'RdBu': color_scale = 'RdBu'\n",
    "    elif cmap == 'OrRd': color_scale = 'OrRd'\n",
    "    elif cmap == 'YlGn': color_scale = 'YlGn'\n",
    "    elif cmap == 'Purples': color_scale = 'Purples'\n",
    "    elif cmap == 'Blues': color_scale = 'Blues'\n",
    "    elif cmap == 'Greens': color_scale = 'Greens'\n",
    "    elif cmap == 'magma': color_scale = 'Magma'\n",
    "    elif cmap == 'viridis': color_scale = 'Viridis'\n",
    "    \n",
    "    # Determine range\n",
    "    range_color = [vmin, vmax] if vmin is not None and vmax is not None else None\n",
    "\n",
    "    if categorical:\n",
    "        fig = px.choropleth_mapbox(\n",
    "            gdf_4326,\n",
    "            geojson=gdf_4326.geometry,\n",
    "            locations=gdf_4326.index,\n",
    "            color=column,\n",
    "            hover_name='Freguesia_Norm',\n",
    "            hover_data={column: True},\n",
    "            title=title,\n",
    "            mapbox_style=\"carto-positron\",\n",
    "            center={\"lat\": 38.7223, \"lon\": -9.1393},\n",
    "            zoom=11,\n",
    "            opacity=0.7,\n",
    "            color_discrete_sequence=px.colors.qualitative.Bold\n",
    "        )\n",
    "    else:\n",
    "        fig = px.choropleth_mapbox(\n",
    "            gdf_4326,\n",
    "            geojson=gdf_4326.geometry,\n",
    "            locations=gdf_4326.index,\n",
    "            color=column,\n",
    "            hover_name='Freguesia_Norm',\n",
    "            hover_data={column: True},\n",
    "            title=title,\n",
    "            mapbox_style=\"carto-positron\",\n",
    "            center={\"lat\": 38.7223, \"lon\": -9.1393},\n",
    "            zoom=11,\n",
    "            opacity=0.7,\n",
    "            color_continuous_scale=color_scale,\n",
    "            range_color=range_color\n",
    "        )\n",
    "        \n",
    "    fig.update_layout(margin={\"r\":0,\"t\":40,\"l\":0,\"b\":0})\n",
    "    fig.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Map clipped to remove water areas. Areas recalculated.\n"
     ]
    }
   ],
   "source": [
    "# 0. LOAD BASE GEOMETRY\n",
    "from shapely.geometry import Polygon\n",
    "\n",
    "freguesias_path = \"../data/boundaries/lisboa_freguesias_oficial.geojson\"\n",
    "freguesias_gdf = gpd.read_file(freguesias_path).to_crs(\"EPSG:3763\")\n",
    "name_col = 'Des_Simpli' if 'Des_Simpli' in freguesias_gdf.columns else 'Freguesia'\n",
    "freguesias_gdf = normalize_freguesia(freguesias_gdf, name_col)\n",
    "\n",
    "# --- MANUAL CLIP WATER (Tagus River) ---\n",
    "# Since we lack a precise land mask, we approximate the river boundary to fix densities.\n",
    "# Coordinates are approximate trace of the coastline.\n",
    "coast_points = [\n",
    "    (-9.300, 38.690), # West limit\n",
    "    (-9.235, 38.691), # Belém Tower area\n",
    "    (-9.180, 38.695), # Alcântara\n",
    "    (-9.150, 38.703), # Terreiro do Paço\n",
    "    (-9.120, 38.710), # Santa Apolónia\n",
    "    (-9.100, 38.735), # Beato/Marvila\n",
    "    (-9.090, 38.750), # Braço de Prata\n",
    "    (-9.085, 38.790), # Parque das Nações\n",
    "    (-9.085, 38.850), # North limit (river side)\n",
    "    (-8.900, 38.850), # East\n",
    "    (-8.900, 38.500), # South East\n",
    "    (-9.300, 38.500)  # South West\n",
    "]\n",
    "\n",
    "water_poly = Polygon(coast_points)\n",
    "water_gdf = gpd.GeoDataFrame({'geometry': [water_poly]}, crs=\"EPSG:4326\").to_crs(\"EPSG:3763\")\n",
    "\n",
    "# Clip (Difference)\n",
    "freguesias_gdf = gpd.overlay(freguesias_gdf, water_gdf, how='difference')\n",
    "\n",
    "# Recalculate Area\n",
    "freguesias_gdf['Area_km2'] = freguesias_gdf.geometry.area / 10**6\n",
    "\n",
    "# Master DataFrame for aggregations\n",
    "master_stats = freguesias_gdf[['Freguesia_Norm', 'geometry', 'Area_km2', name_col]].copy()\n",
    "\n",
    "print(\"Map clipped to remove water areas. Areas recalculated.\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--- 9. Cluster Analysis ---\n",
      "Clustering with features: ['Pop_Density', 'Tourism_Density', 'Transport_Score']\n"
     ]
    },
    {
     "ename": "KeyError",
     "evalue": "\"None of [Index(['Pop_Density', 'Tourism_Density', 'Transport_Score'], dtype='object')] are in the [columns]\"",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mKeyError\u001b[39m                                  Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[3]\u001b[39m\u001b[32m, line 15\u001b[39m\n\u001b[32m     12\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[33m'\u001b[39m\u001b[33mRent_Price_m2\u001b[39m\u001b[33m'\u001b[39m \u001b[38;5;129;01min\u001b[39;00m master_stats.columns: features.append(\u001b[33m'\u001b[39m\u001b[33mRent_Price_m2\u001b[39m\u001b[33m'\u001b[39m)\n\u001b[32m     14\u001b[39m \u001b[38;5;28mprint\u001b[39m(\u001b[33mf\u001b[39m\u001b[33m\"\u001b[39m\u001b[33mClustering with features: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mfeatures\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m\"\u001b[39m)\n\u001b[32m---> \u001b[39m\u001b[32m15\u001b[39m data_for_clustering = \u001b[43mmaster_stats\u001b[49m\u001b[43m.\u001b[49m\u001b[43mset_index\u001b[49m\u001b[43m(\u001b[49m\u001b[33;43m'\u001b[39;49m\u001b[33;43mDes_Simpli\u001b[39;49m\u001b[33;43m'\u001b[39;49m\u001b[43m)\u001b[49m\u001b[43m[\u001b[49m\u001b[43mfeatures\u001b[49m\u001b[43m]\u001b[49m.dropna()\n\u001b[32m     17\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m data_for_clustering.empty:\n\u001b[32m     18\u001b[39m     scaler = StandardScaler()\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/miniforge3/lib/python3.12/site-packages/geopandas/geodataframe.py:1896\u001b[39m, in \u001b[36mGeoDataFrame.__getitem__\u001b[39m\u001b[34m(self, key)\u001b[39m\n\u001b[32m   1890\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34m__getitem__\u001b[39m(\u001b[38;5;28mself\u001b[39m, key):\n\u001b[32m   1891\u001b[39m \u001b[38;5;250m    \u001b[39m\u001b[33;03m\"\"\"\u001b[39;00m\n\u001b[32m   1892\u001b[39m \u001b[33;03m    If the result is a column containing only 'geometry', return a\u001b[39;00m\n\u001b[32m   1893\u001b[39m \u001b[33;03m    GeoSeries. If it's a DataFrame with any columns of GeometryDtype,\u001b[39;00m\n\u001b[32m   1894\u001b[39m \u001b[33;03m    return a GeoDataFrame.\u001b[39;00m\n\u001b[32m   1895\u001b[39m \u001b[33;03m    \"\"\"\u001b[39;00m\n\u001b[32m-> \u001b[39m\u001b[32m1896\u001b[39m     result = \u001b[38;5;28;43msuper\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[43m.\u001b[49m\u001b[34;43m__getitem__\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mkey\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m   1897\u001b[39m     \u001b[38;5;66;03m# Custom logic to avoid waiting for pandas GH51895\u001b[39;00m\n\u001b[32m   1898\u001b[39m     \u001b[38;5;66;03m# result is not geometry dtype for multi-indexes\u001b[39;00m\n\u001b[32m   1899\u001b[39m     \u001b[38;5;28;01mif\u001b[39;00m (\n\u001b[32m   1900\u001b[39m         pd.api.types.is_scalar(key)\n\u001b[32m   1901\u001b[39m         \u001b[38;5;129;01mand\u001b[39;00m key == \u001b[33m\"\u001b[39m\u001b[33m\"\u001b[39m\n\u001b[32m   (...)\u001b[39m\u001b[32m   1904\u001b[39m         \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m is_geometry_type(result)\n\u001b[32m   1905\u001b[39m     ):\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/miniforge3/lib/python3.12/site-packages/pandas/core/frame.py:4113\u001b[39m, in \u001b[36mDataFrame.__getitem__\u001b[39m\u001b[34m(self, key)\u001b[39m\n\u001b[32m   4111\u001b[39m     \u001b[38;5;28;01mif\u001b[39;00m is_iterator(key):\n\u001b[32m   4112\u001b[39m         key = \u001b[38;5;28mlist\u001b[39m(key)\n\u001b[32m-> \u001b[39m\u001b[32m4113\u001b[39m     indexer = \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mcolumns\u001b[49m\u001b[43m.\u001b[49m\u001b[43m_get_indexer_strict\u001b[49m\u001b[43m(\u001b[49m\u001b[43mkey\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mcolumns\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m)\u001b[49m[\u001b[32m1\u001b[39m]\n\u001b[32m   4115\u001b[39m \u001b[38;5;66;03m# take() does not accept boolean indexers\u001b[39;00m\n\u001b[32m   4116\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mgetattr\u001b[39m(indexer, \u001b[33m\"\u001b[39m\u001b[33mdtype\u001b[39m\u001b[33m\"\u001b[39m, \u001b[38;5;28;01mNone\u001b[39;00m) == \u001b[38;5;28mbool\u001b[39m:\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/miniforge3/lib/python3.12/site-packages/pandas/core/indexes/base.py:6212\u001b[39m, in \u001b[36mIndex._get_indexer_strict\u001b[39m\u001b[34m(self, key, axis_name)\u001b[39m\n\u001b[32m   6209\u001b[39m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[32m   6210\u001b[39m     keyarr, indexer, new_indexer = \u001b[38;5;28mself\u001b[39m._reindex_non_unique(keyarr)\n\u001b[32m-> \u001b[39m\u001b[32m6212\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_raise_if_missing\u001b[49m\u001b[43m(\u001b[49m\u001b[43mkeyarr\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mindexer\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43maxis_name\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m   6214\u001b[39m keyarr = \u001b[38;5;28mself\u001b[39m.take(indexer)\n\u001b[32m   6215\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(key, Index):\n\u001b[32m   6216\u001b[39m     \u001b[38;5;66;03m# GH 42790 - Preserve name from an Index\u001b[39;00m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/miniforge3/lib/python3.12/site-packages/pandas/core/indexes/base.py:6261\u001b[39m, in \u001b[36mIndex._raise_if_missing\u001b[39m\u001b[34m(self, key, indexer, axis_name)\u001b[39m\n\u001b[32m   6259\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m nmissing:\n\u001b[32m   6260\u001b[39m     \u001b[38;5;28;01mif\u001b[39;00m nmissing == \u001b[38;5;28mlen\u001b[39m(indexer):\n\u001b[32m-> \u001b[39m\u001b[32m6261\u001b[39m         \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mKeyError\u001b[39;00m(\u001b[33mf\u001b[39m\u001b[33m\"\u001b[39m\u001b[33mNone of [\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mkey\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m] are in the [\u001b[39m\u001b[38;5;132;01m{\u001b[39;00maxis_name\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m]\u001b[39m\u001b[33m\"\u001b[39m)\n\u001b[32m   6263\u001b[39m     not_found = \u001b[38;5;28mlist\u001b[39m(ensure_index(key)[missing_mask.nonzero()[\u001b[32m0\u001b[39m]].unique())\n\u001b[32m   6264\u001b[39m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mKeyError\u001b[39;00m(\u001b[33mf\u001b[39m\u001b[33m\"\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mnot_found\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m not in index\u001b[39m\u001b[33m\"\u001b[39m)\n",
      "\u001b[31mKeyError\u001b[39m: \"None of [Index(['Pop_Density', 'Tourism_Density', 'Transport_Score'], dtype='object')] are in the [columns]\""
     ]
    }
   ],
   "source": [
    "# 9. CLUSTER ANALYSIS (The \"Coolest\" Neighborhood)\n",
    "print(\"--- 9. Cluster Analysis ---\")\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.cluster import KMeans\n",
    "\n",
    "# Select features\n",
    "features = ['Pop_Density', 'Tourism_Density', 'Transport_Score']\n",
    "if 'Avg_Noise' in master_stats.columns: features.append('Avg_Noise')\n",
    "if 'Culture_Density' in master_stats.columns: features.append('Culture_Density')\n",
    "if 'Green_Score' in master_stats.columns: features.append('Green_Score')\n",
    "if 'Service_Density' in master_stats.columns: features.append('Service_Density')\n",
    "if 'Rent_Price_m2' in master_stats.columns: features.append('Rent_Price_m2')\n",
    "\n",
    "print(f\"Clustering with features: {features}\")\n",
    "data_for_clustering = master_stats.set_index('Des_Simpli')[features].dropna()\n",
    "\n",
    "if not data_for_clustering.empty:\n",
    "    scaler = StandardScaler()\n",
    "    scaled_data = scaler.fit_transform(data_for_clustering)\n",
    "\n",
    "    # Simple K-Means\n",
    "    kmeans = KMeans(n_clusters=4, random_state=42)\n",
    "    data_for_clustering['Cluster'] = kmeans.fit_predict(scaled_data)\n",
    "\n",
    "    # Join back\n",
    "    master_stats = master_stats.merge(data_for_clustering[['Cluster']], left_on='Des_Simpli', right_index=True, how='left')\n",
    "\n",
    "    # Map Clusters\n",
    "    master_stats['Cluster'] = master_stats['Cluster'].fillna(-1).astype(str) # -1 for missing\n",
    "    \n",
    "    fig_clus = px.choropleth_mapbox(\n",
    "        master_stats, geojson=master_stats.geometry, locations=master_stats.index,\n",
    "        color='Cluster',\n",
    "        center={\"lat\": 38.7223, \"lon\": -9.1393},\n",
    "        mapbox_style=\"carto-positron\", zoom=11,\n",
    "        opacity=0.7,\n",
    "        hover_name='Des_Simpli',\n",
    "        hover_data=features,\n",
    "        title=\"9.1 Neighborhood Clusters\"\n",
    "    )\n",
    "    fig_clus.update_layout(margin={\"r\":0,\"t\":40,\"l\":0,\"b\":0})\n",
    "    fig_clus.show()\n",
    "\n",
    "    # Profiling Clusters\n",
    "    numeric_cols = features\n",
    "    cluster_profile = data_for_clustering.groupby('Cluster')[numeric_cols].mean()\n",
    "    print(\"Cluster Profiles (Mean Values):\")\n",
    "    print(cluster_profile)\n",
    "\n",
    "    # Identify \"Coolest\" (e.g., High Culture, High Green, Moderate Tourism)\n",
    "    # This is subjective, but we can define a score\n",
    "    # Score = Culture + Green + Transport - Noise - (Tourism * 0.5)\n",
    "    \n",
    "    # Normalize again for scoring\n",
    "    norm_df = data_for_clustering.copy()\n",
    "    for c in numeric_cols:\n",
    "        norm_df[c] = (norm_df[c] - norm_df[c].min()) / (norm_df[c].max() - norm_df[c].min())\n",
    "    \n",
    "    norm_df['Cool_Score'] = (\n",
    "        norm_df.get('Culture_Density', 0) + \n",
    "        norm_df.get('Green_Score', 0) + \n",
    "        norm_df.get('Transport_Score', 0) +\n",
    "        norm_df.get('Service_Density', 0) -\n",
    "        norm_df.get('Avg_Noise', 0)\n",
    "    )\n",
    "    \n",
    "    top_hoods = norm_df.sort_values('Cool_Score', ascending=False).head(5)\n",
    "    print(\" Top 5 'Coolest' Neighborhoods based on composite score:\")\n",
    "    print(top_hoods[['Cool_Score']])\n",
    "else:\n",
    "    print(\"Not enough data for clustering.\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Conclusion\n",
    "This notebook integrates multiple geospatial datasets to analyze Lisbon's neighborhoods. \n",
    "We explored:\n",
    "- **Demographics**: Where people live and how it's changing.\n",
    "- **Tourism**: The impact of short-term rentals.\n",
    "- **Mobility**: Accessibility via public transport.\n",
    "- **Culture & Leisure**: Distribution of cultural venues and green spaces.\n",
    "- **Services**: Availability of essential services.\n",
    "\n",
    "The **Cluster Analysis** helps group similar neighborhoods, identifying areas that might be gentrified (high tourism, high rent), residential havens (high green, low noise), or cultural hotspots.\n",
    "The \"Coolest Neighborhood\" score attempts to quantify livability based on a mix of positive amenities and negative externalities like noise.\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
